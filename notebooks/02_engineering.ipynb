{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Recommendation System for Purchase Data\n",
    "\n",
    "The scope of this notebook is \n",
    "\n",
    "- Prepare the Scoring Function\n",
    "- Unit Test the Score\n",
    "- Build Flask Scoring App and deploy as a Web End point\n",
    "- Build Dash App and deploy as Interactive Web Services\n",
    "\n",
    "The Business case is an mobile app allowing its customers to place orders before they even have to walk into the store.\n",
    "When a customer first taps on the “order” page, we may recommend \n",
    "\n",
    "- Personalized recommendation with ranked list of items (product IDs) that the user is most likely to want to put in his/her (empty) “basket”\n",
    "\n",
    "Assuming that the scenario is ModelOps 0. Then: \n",
    "\n",
    "1. Data scientists hand over a trained model as an artifact to the engineering team for deployement\n",
    "2. The handoff can include putting the trained model in the models registry\n",
    "3. The Scoring process is in Batch on a sigle EC2 instance\n",
    "\n",
    "We have to reproduce the required development enviroment\n",
    "\n",
    "0. Define Artefacter function to get the last version of Champion Model (optional)\n",
    "\n",
    "1. Define Scoring Functions: Batch scoring is the main assumption\n",
    "\n",
    "    - Define the get_top_items function \n",
    "    - Define the get_top_n_ui function\n",
    "    \n",
    "\n",
    "2. Unit Test \n",
    "\n",
    "3. Define a quick front end that simulate Mobile App (Test it in Docker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "import sqlalchemy as sql\n",
    "\n",
    "#Data Science\n",
    "import pandas as pd\n",
    "from surprise import dump\n",
    "\n",
    "#Model Tracking\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "#ML engineering\n",
    "import flask\n",
    "\n",
    "#Utils\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import configparser\n",
    "import json\n",
    "import pickle\n",
    "import unittest\n",
    "import docker\n",
    "import pprint\n",
    "import time\n",
    "import requests\n",
    "\n",
    "#Settings\n",
    "from pprint import pprint\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment variables\n",
    "outmodels = '../models/'\n",
    "app_folder = '../src/app'\n",
    "\n",
    "# Set dbconnection variables\n",
    "dbconnPath = './dbconn.properties'\n",
    "config = configparser.RawConfigParser()\n",
    "config.read(dbconnPath)\n",
    "params = config\n",
    "db_host=params.get('CONN', 'host')\n",
    "db_port=params.get('CONN', 'port')\n",
    "db_user=params.get('CONN', 'user')\n",
    "db_pwd=params.get('CONN', 'password')\n",
    "db_name=params.get('CONN', 'database')\n",
    "\n",
    "# Set connection string\n",
    "connection_str = f'mysql+pymysql://{db_user}:{db_pwd}@{db_host}:{db_port}/{db_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Model Artefact from Mlflow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "for regmodel in client.list_registered_models():\n",
    "    regmodel_info = dict(regmodel)\n",
    "\n",
    "# pprint(regmodel_info, indent=3)\n",
    "\n",
    "champion=client.get_registered_model('Champion')\n",
    "championid=champion.latest_versions[-1].run_id\n",
    "\n",
    "art_list = [arts.path for arts in client.list_artifacts(championid, path=None)]\n",
    "\n",
    "for art_path in art_list: \n",
    "    client.download_artifacts(championid, art_path, outmodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Model Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample of Predictions: \n",
      "\n",
      " [Prediction(uid='100', iid='0', r_ui=1.0, est=1.4104866760238497, details={'was_impossible': False}), Prediction(uid='100', iid='118', r_ui=2.0, est=1.6290418315812665, details={'was_impossible': False}), Prediction(uid='100', iid='201', r_ui=1.0, est=1.0281647548199493, details={'was_impossible': False}), Prediction(uid='100', iid='24', r_ui=2.0, est=1.065194864590783, details={'was_impossible': False}), Prediction(uid='100', iid='27', r_ui=4.0, est=1.4686861264367166, details={'was_impossible': False}), Prediction(uid='100', iid='282', r_ui=6.0, est=1.2631693065495946, details={'was_impossible': False}), Prediction(uid='100', iid='51', r_ui=0.0, est=1.3060476975670121, details={'was_impossible': False}), Prediction(uid='100', iid='6', r_ui=0.0, est=1.8579018429484466, details={'was_impossible': False}), Prediction(uid='100', iid='62', r_ui=2.0, est=1.0656423124377505, details={'was_impossible': False}), Prediction(uid='100', iid='67', r_ui=3.0, est=1.5598915237397826, details={'was_impossible': False})]\n",
      "\n",
      " Number of predictions: 133585\n"
     ]
    }
   ],
   "source": [
    "modelpkl = [modelpath for modelpath in glob.glob(outmodels + 'model/*.pkl')][0]\n",
    "modelpkl\n",
    "\n",
    "predictions, algo = dump.load(modelpkl)\n",
    "\n",
    "print('\\n')\n",
    "print('Sample of Predictions: ')\n",
    "print('\\n', predictions[0:10])\n",
    "print('\\n', 'Number of predictions:', len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Function\n",
    "\n",
    "We have to return Top 10 Recommended Items by userid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(predictions, n=10):\n",
    "    \n",
    "    '''\n",
    "    Returns the the top-N recommendation from a set of predictions\n",
    "    \n",
    "    '''\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "        \n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "        \n",
    "    return top_n\n",
    "\n",
    "def get_top_n_ui(top, uid):\n",
    "    try:\n",
    "        top_n_ui = [[iid for (iid, _) in user_ratings] for UID, user_ratings in top.items() if UID==uid][0]\n",
    "        return top_n_ui\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.247s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fae79b30510>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestScoreFunction(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.testcase = \"100\"\n",
    "        self.expected = ['6', '118', '67', '27', '0', '51', '282', '62', '24', '201']\n",
    "    \n",
    "    def test_empty(self):\n",
    "        self.assertTrue(bool(get_top_n_ui(get_top(predictions), self.testcase)))\n",
    "\n",
    "    def test_basic(self):\n",
    "        self.assertEqual(get_top_n_ui(get_top(predictions), self.testcase), self.expected)\n",
    "        \n",
    "unittest.main(argv = ['first-arg-is-ignored'], exit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Rank</th>\n",
       "      <th>Product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1° Product</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2° Product</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3° Product</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4° Product</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5° Product</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6° Product</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7° Product</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8° Product</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9° Product</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product_Rank Product_id\n",
       "0   1° Product          6\n",
       "1   2° Product        118\n",
       "2   3° Product         67\n",
       "3   4° Product         27\n",
       "4   5° Product          0\n",
       "5   6° Product         51\n",
       "6   7° Product        282\n",
       "7   8° Product         62\n",
       "8   9° Product         24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcase = \"100\"\n",
    "test_preds = get_top_n_ui(get_top(predictions), testcase)\n",
    "test_preds\n",
    "\n",
    "pred_len = len(test_preds)\n",
    "pred_names = [\"\".join([str(i), \"°\", \" Product\"]) for i in range(1,pred_len)]\n",
    "\n",
    "pd.DataFrame(list(zip(pred_names, test_preds)), columns=['Product_Rank', 'Product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.354s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fae79b30350>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestScoreFunction(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.testcase = \"100\"\n",
    "        self.expected = ['6', '118', '67', '27', '0', '51', '282', '62', '24', '201']\n",
    "    \n",
    "    def test_empty(self):\n",
    "        self.assertTrue(bool(get_top_n_ui(get_top(predictions), self.testcase)))\n",
    "\n",
    "    def test_basic(self):\n",
    "        self.assertEqual(get_top_n_ui(get_top(predictions), self.testcase), self.expected)\n",
    "        \n",
    "unittest.main(argv = ['first-arg-is-ignored'], exit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Scoring Flask App and deploy as web endpoint\n",
    "\n",
    "Because we're testing, I need a app folder with:\n",
    "\n",
    "1. app.py\n",
    "2. requirements.txt\n",
    "3. Dockerfile\n",
    "\n",
    "Then run the application with Docker Client and test it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a app folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(app_folder):\n",
    "    os.makedirs(app_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(app_folder + '/model'):\n",
    "    shutil.copytree(src=outmodels + 'model', dst=app_folder + '/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(app_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import flask\n",
    "\n",
    "#create an instance\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "def locate_model(dest):\n",
    "    \n",
    "    '''\n",
    "    Locate model pickle file\n",
    "    \n",
    "    '''\n",
    "    for dirpath, dirnames, filenames in os.walk(dest):\n",
    "        for filename in [f for f in filenames if f.endswith((\".pkl\", \".pickle\"))]:\n",
    "            model_path = os.path.join(dirpath, filename)\n",
    "            return model_path\n",
    "    return None\n",
    "\n",
    "def model_reader(model_path):\n",
    "    predictions, algo = dump.load(model_path)\n",
    "    return predictions, algo\n",
    "\n",
    "def get_top(predictions, n=10):\n",
    "    \n",
    "    '''\n",
    "    Returns the the top-N recommendation from a set of predictions\n",
    "    \n",
    "    '''\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "        \n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "        \n",
    "    return top_n\n",
    "\n",
    "def get_top_n_ui(top, uid):\n",
    "    try:\n",
    "        top_n_ui = [[iid for (iid, _) in user_ratings] for UID, user_ratings in top.items() if UID==uid][0]\n",
    "        return top_n_ui\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "\n",
    "@app.route('/predict', methods=['GET','POST'])\n",
    "def predict():\n",
    "    \n",
    "    logging.info('Scoring Application is starting to process the request')\n",
    "    \n",
    "    #Intiate variables\n",
    "    data = defaultdict()\n",
    "    data[\"success\"] = False\n",
    "    params = flask.request.args\n",
    "    \n",
    "    if 'uid' in params.keys():\n",
    "        uid_toscore = str(params.get('uid'))\n",
    "        model_path = locate_model(os.getcwd())\n",
    "        predictions, _ = model_reader(model_path)\n",
    "        uid_predictions = get_top_n_ui(get_top(predictions), uid_toscore)\n",
    "        \n",
    "        prediction_rank_lenght = len(uid_predictions)\n",
    "        prediction_rank_labels = [\"\".join([str(i), \"°\", \" Product\"]) for i in range(1,prediction_rank_lenght)]\n",
    "        products_recommended = pd.DataFrame(list(zip(prediction_rank_labels, uid_predictions)), columns=['Product_Rank', 'Product_id'])\n",
    "    \n",
    "    return flask.jsonify(products_recommended)\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=9999, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n",
      "1.0.4\n"
     ]
    }
   ],
   "source": [
    "print(flask.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "flask==1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile Dockerfile\n",
    "\n",
    "# FROM ubuntu:16.04\n",
    "\n",
    "# RUN apt-get update -y && \\\n",
    "#     apt-get install -y python-pip python-dev\n",
    "\n",
    "# COPY ./requirements.txt /app/requirements.txt\n",
    "\n",
    "# WORKDIR /app\n",
    "\n",
    "# RUN pip install -r requirements.txt\n",
    "\n",
    "# COPY . /app\n",
    "\n",
    "# ENV FLASK_APP=app.py\n",
    "\n",
    "# ENTRYPOINT [ \"python\" ]\n",
    "\n",
    "# CMD [ \"app.py\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM conda/miniconda3:latest\n",
    "\n",
    "LABEL Python - score app\n",
    "\n",
    "USER root\n",
    "\n",
    "COPY . /app\n",
    "\n",
    "RUN pip install --upgrade pip;\n",
    "    \n",
    "RUN pip install -r requirements.txt;\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "ENV FLASK_APP=app.py\n",
    "\n",
    "ENTRYPOINT [ \"python\" ]\n",
    "\n",
    "CMD [ \"app.py\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "BuildError",
     "evalue": "The command '/bin/sh -c pip install -r requirements.txt;' returned a non-zero code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBuildError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-cf964fa7ab25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdockercli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#if not build it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdockercli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdockercli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/docker/models/images.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minternal_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mBuildError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'stream'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 match = re.search(\n",
      "\u001b[0;31mBuildError\u001b[0m: The command '/bin/sh -c pip install -r requirements.txt;' returned a non-zero code: 1"
     ]
    }
   ],
   "source": [
    "image_name = \"score-flask_app:1\"\n",
    "\n",
    "#Client instance\n",
    "dockercli = docker.DockerClient()\n",
    "\n",
    "#Check for image\n",
    "if not dockercli.images.list(image_name):\n",
    "    #if not build it\n",
    "    dockercli.images.build(path='.', tag = image_name)\n",
    "else:\n",
    "    dockercli.images.remove(image_name, force = True)\n",
    "    dockercli.images.build(path='.', tag = image_name)\n",
    "try:\n",
    "    app_container = dockercli.containers.run(image_name, name='scoring_app_test', detach=True, ports={'9999/tcp': 9999})\n",
    "    status = app_container.attrs\n",
    "    print(status['State'])\n",
    "    while (status['State']['Running'] == False):\n",
    "        time.sleep(3)\n",
    "        app_container.reload()\n",
    "        status = app_container.attrs\n",
    "        print(''.center(50, '-'))\n",
    "        print(status['State'])\n",
    "except RuntimeError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Flask Scoring App as web endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = input(\"Please provide protocol (http/https) \")\n",
    "server = input(\"Please provide server ip \")\n",
    "port = input(\"Please provide port \")\n",
    "\n",
    "# Check that the container is available\n",
    "score_request = requests.get(protocol + \"://\" + server + \":\" + port + \"/predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_request.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kill the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app_container' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6c5b17f720d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# stop and remove the container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mapp_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mapp_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'app_container' is not defined"
     ]
    }
   ],
   "source": [
    "# stop and remove the container\n",
    "app_container.stop()\n",
    "app_container.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "# viewer = JupyterDash.AppViewer()\n",
    "\n",
    "# app = dash.Dash(__name__)\n",
    "\n",
    "# app.layout = html.Div('Hello World')\n",
    "\n",
    "# viewer.show(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://plotly.github.io/datasets/country_indicators.csv')\n",
    "available_indicators = df['Indicator Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "# Create server variable with Flask server object for use with gunicorn\n",
    "server = app.server\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                id='crossfilter-xaxis-column',\n",
    "                options=[{'label': i, 'value': i} for i in available_indicators],\n",
    "                value='Fertility rate, total (births per woman)'\n",
    "            ),\n",
    "            dcc.RadioItems(\n",
    "                id='crossfilter-xaxis-type',\n",
    "                options=[{'label': i, 'value': i} for i in ['Linear', 'Log']],\n",
    "                value='Linear',\n",
    "                labelStyle={'display': 'inline-block'}\n",
    "            )\n",
    "        ],\n",
    "        style={'width': '49%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                id='crossfilter-yaxis-column',\n",
    "                options=[{'label': i, 'value': i} for i in available_indicators],\n",
    "                value='Life expectancy at birth, total (years)'\n",
    "            ),\n",
    "            dcc.RadioItems(\n",
    "                id='crossfilter-yaxis-type',\n",
    "                options=[{'label': i, 'value': i} for i in ['Linear', 'Log']],\n",
    "                value='Linear',\n",
    "                labelStyle={'display': 'inline-block'}\n",
    "            )\n",
    "        ], style={'width': '49%', 'float': 'right', 'display': 'inline-block'})\n",
    "    ], style={\n",
    "        'borderBottom': 'thin lightgrey solid',\n",
    "        'backgroundColor': 'rgb(250, 250, 250)',\n",
    "        'padding': '10px 5px'\n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        dcc.Graph(\n",
    "            id='crossfilter-indicator-scatter',\n",
    "            hoverData={'points': [{'customdata': 'Japan'}]}\n",
    "        )\n",
    "    ], style={'width': '49%', 'display': 'inline-block', 'padding': '0 20'}),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='x-time-series'),\n",
    "        dcc.Graph(id='y-time-series'),\n",
    "    ], style={'display': 'inline-block', 'width': '49%'}),\n",
    "\n",
    "    html.Div(dcc.Slider(\n",
    "        id='crossfilter-year--slider',\n",
    "        min=df['Year'].min(),\n",
    "        max=df['Year'].max(),\n",
    "        value=df['Year'].max(),\n",
    "        marks={str(year): str(year) for year in df['Year'].unique()},\n",
    "        step=None\n",
    "    ), style={'width': '49%', 'padding': '0px 20px 20px 20px'})\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('crossfilter-indicator-scatter', 'figure'),\n",
    "    [dash.dependencies.Input('crossfilter-xaxis-column', 'value'),\n",
    "     dash.dependencies.Input('crossfilter-yaxis-column', 'value'),\n",
    "     dash.dependencies.Input('crossfilter-xaxis-type', 'value'),\n",
    "     dash.dependencies.Input('crossfilter-yaxis-type', 'value'),\n",
    "     dash.dependencies.Input('crossfilter-year--slider', 'value')])\n",
    "def update_graph(xaxis_column_name, yaxis_column_name,\n",
    "                 xaxis_type, yaxis_type,\n",
    "                 year_value):\n",
    "    dff = df[df['Year'] == year_value]\n",
    "\n",
    "    return {\n",
    "        'data': [dict(\n",
    "            x=dff[dff['Indicator Name'] == xaxis_column_name]['Value'],\n",
    "            y=dff[dff['Indicator Name'] == yaxis_column_name]['Value'],\n",
    "            text=dff[dff['Indicator Name'] == yaxis_column_name]['Country Name'],\n",
    "            customdata=dff[dff['Indicator Name'] == yaxis_column_name]['Country Name'],\n",
    "            mode='markers',\n",
    "            marker={\n",
    "                'size': 25,\n",
    "                'opacity': 0.7,\n",
    "                'color': 'orange',\n",
    "                'line': {'width': 2, 'color': 'purple'}\n",
    "            }\n",
    "        )],\n",
    "        'layout': dict(\n",
    "            xaxis={\n",
    "                'title': xaxis_column_name,\n",
    "                'type': 'linear' if xaxis_type == 'Linear' else 'log'\n",
    "            },\n",
    "            yaxis={\n",
    "                'title': yaxis_column_name,\n",
    "                'type': 'linear' if yaxis_type == 'Linear' else 'log'\n",
    "            },\n",
    "            margin={'l': 40, 'b': 30, 't': 10, 'r': 0},\n",
    "            height=450,\n",
    "            hovermode='closest'\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "def create_time_series(dff, axis_type, title):\n",
    "    return {\n",
    "        'data': [dict(\n",
    "            x=dff['Year'],\n",
    "            y=dff['Value'],\n",
    "            mode='lines+markers'\n",
    "        )],\n",
    "        'layout': {\n",
    "            'height': 225,\n",
    "            'margin': {'l': 20, 'b': 30, 'r': 10, 't': 10},\n",
    "            'annotations': [{\n",
    "                'x': 0, 'y': 0.85, 'xanchor': 'left', 'yanchor': 'bottom',\n",
    "                'xref': 'paper', 'yref': 'paper', 'showarrow': False,\n",
    "                'align': 'left', 'bgcolor': 'rgba(255, 255, 255, 0.5)',\n",
    "                'text': title\n",
    "            }],\n",
    "            'yaxis': {'type': 'linear' if axis_type == 'Linear' else 'log'},\n",
    "            'xaxis': {'showgrid': False}\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('x-time-series', 'figure'),\n",
    "    [dash.dependencies.Input('crossfilter-indicator-scatter', 'hoverData'),\n",
    "     dash.dependencies.Input('crossfilter-xaxis-column', 'value'),\n",
    "     dash.dependencies.Input('crossfilter-xaxis-type', 'value')])\n",
    "def update_y_timeseries(hoverData, xaxis_column_name, axis_type):\n",
    "    country_name = hoverData['points'][0]['customdata']\n",
    "    dff = df[df['Country Name'] == country_name]\n",
    "    dff = dff[dff['Indicator Name'] == xaxis_column_name]\n",
    "    title = '<b>{}</b><br>{}'.format(country_name, xaxis_column_name)\n",
    "    return create_time_series(dff, axis_type, title)\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('y-time-series', 'figure'),\n",
    "    [dash.dependencies.Input('crossfilter-indicator-scatter', 'hoverData'),\n",
    "     dash.dependencies.Input('crossfilter-yaxis-column', 'value'),\n",
    "     dash.dependencies.Input('crossfilter-yaxis-type', 'value')])\n",
    "def update_x_timeseries(hoverData, yaxis_column_name, axis_type):\n",
    "    dff = df[df['Country Name'] == hoverData['points'][0]['customdata']]\n",
    "    dff = dff[dff['Indicator Name'] == yaxis_column_name]\n",
    "    return create_time_series(dff, axis_type, yaxis_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run_server(mode=\"jupyterlab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
