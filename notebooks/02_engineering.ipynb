{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build a Recommendation System for Purchase Data\n",
    "\n",
    "The scope of this notebook is \n",
    "\n",
    "- Prepare the Scoring Function\n",
    "- Unit Test the Score\n",
    "- Build the Dash Application\n",
    "\n",
    "The Business case is an mobile app allowing its customers to place orders before they even have to walk into the store.\n",
    "When a customer first taps on the “order” page, we may recommend \n",
    "\n",
    "- Personalized recommendation with ranked list of items (product IDs) that the user is most likely to want to put in his/her (empty) “basket”\n",
    "\n",
    "Assuming that the scenario is ModelOps 0. Then: \n",
    "\n",
    "1. Data scientists hand over a trained model as an artifact to the engineering team for deployement\n",
    "2. The handoff can include putting the trained model in the models registry\n",
    "3. The Scoring process is in Batch on a sigle EC2 instance\n",
    "\n",
    "We have to reproduce the required development enviroment\n",
    "\n",
    "0. Define Artefacter function to get the last version of Champion Model (optional)\n",
    "\n",
    "1. Define Scoring Functions: Batch scoring is the main assumption\n",
    "\n",
    "    - Define the get_top_items function \n",
    "    - Define the get_top_n_ui function\n",
    "    \n",
    "\n",
    "2. Unit Test \n",
    "\n",
    "3. Define a quick front end that simulate Mobile App (Test it in Docker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "import sqlalchemy as sql\n",
    "\n",
    "#Data Science\n",
    "import pandas as pd\n",
    "from surprise import dump\n",
    "\n",
    "#Model Tracking\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "#Utils\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import configparser\n",
    "import json\n",
    "import pickle\n",
    "import unittest\n",
    "\n",
    "#Settings\n",
    "from pprint import pprint\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment variables\n",
    "outmodels = '../models/'\n",
    "app_folder = '../src/app'\n",
    "\n",
    "# Set dbconnection variables\n",
    "dbconnPath = './dbconn.properties'\n",
    "config = configparser.RawConfigParser()\n",
    "config.read(dbconnPath)\n",
    "params = config\n",
    "db_host=params.get('CONN', 'host')\n",
    "db_port=params.get('CONN', 'port')\n",
    "db_user=params.get('CONN', 'user')\n",
    "db_pwd=params.get('CONN', 'password')\n",
    "db_name=params.get('CONN', 'database')\n",
    "\n",
    "# Set connection string\n",
    "connection_str = f'mysql+pymysql://{db_user}:{db_pwd}@{db_host}:{db_port}/{db_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Model Artefact from Mlflow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "for regmodel in client.list_registered_models():\n",
    "    regmodel_info = dict(regmodel)\n",
    "\n",
    "# pprint(regmodel_info, indent=3)\n",
    "\n",
    "champion=client.get_registered_model('Champion')\n",
    "championid=champion.latest_versions[-1].run_id\n",
    "\n",
    "art_list = [arts.path for arts in client.list_artifacts(championid, path=None)]\n",
    "\n",
    "for art_path in art_list: \n",
    "    client.download_artifacts(championid, art_path, outmodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Model Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid='100', iid='0', r_ui=1.0, est=1.4104866760238497, details={'was_impossible': False}), Prediction(uid='100', iid='118', r_ui=2.0, est=1.6290418315812665, details={'was_impossible': False}), Prediction(uid='100', iid='201', r_ui=1.0, est=1.0281647548199493, details={'was_impossible': False}), Prediction(uid='100', iid='24', r_ui=2.0, est=1.065194864590783, details={'was_impossible': False}), Prediction(uid='100', iid='27', r_ui=4.0, est=1.4686861264367166, details={'was_impossible': False}), Prediction(uid='100', iid='282', r_ui=6.0, est=1.2631693065495946, details={'was_impossible': False}), Prediction(uid='100', iid='51', r_ui=0.0, est=1.3060476975670121, details={'was_impossible': False}), Prediction(uid='100', iid='6', r_ui=0.0, est=1.8579018429484466, details={'was_impossible': False}), Prediction(uid='100', iid='62', r_ui=2.0, est=1.0656423124377505, details={'was_impossible': False}), Prediction(uid='100', iid='67', r_ui=3.0, est=1.5598915237397826, details={'was_impossible': False})]\n",
      "\n",
      " 133585\n",
      "\n",
      " ****************************************************************************************************\n",
      "<surprise.prediction_algorithms.baseline_only.BaselineOnly object at 0x7fe5444b0c50>\n"
     ]
    }
   ],
   "source": [
    "modelpkl = [modelpath for modelpath in glob.glob(outmodels + 'model/*.pkl')][0]\n",
    "modelpkl\n",
    "\n",
    "predictions, algo = dump.load(modelpkl)\n",
    "\n",
    "print(predictions[0:10])\n",
    "print('\\n', len(predictions))\n",
    "print('\\n', '*'*100)\n",
    "print(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Function\n",
    "\n",
    "We have to return Top 10 Recommended Items by userid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(predictions, n=10):\n",
    "    \n",
    "    '''\n",
    "    Returns the the top-N recommendation from a set of predictions\n",
    "    \n",
    "    '''\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "        \n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "        \n",
    "    return top_n\n",
    "\n",
    "def get_top_n_ui(top, uid):\n",
    "    try:\n",
    "        top_n_ui = [[iid for (iid, _) in user_ratings] for UID, user_ratings in top.items() if UID==uid][0]\n",
    "        return top_n_ui\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.322s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fe54c4d1650>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestScoreFunction(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.testcase = \"100\"\n",
    "        self.expected = ['6', '118', '67', '27', '0', '51', '282', '62', '24', '201']\n",
    "    \n",
    "    def test_empty(self):\n",
    "        self.assertTrue(bool(get_top_n_ui(get_top(predictions), self.testcase)))\n",
    "\n",
    "    def test_basic(self):\n",
    "        self.assertEqual(get_top_n_ui(get_top(predictions), self.testcase), self.expected)\n",
    "        \n",
    "unittest.main(argv = ['first-arg-is-ignored'], exit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Scoring Flask App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(app_folder):\n",
    "    os.makedirs(app_folder)\n",
    "os.chdir(app_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "from flask import Flask, jsonify, request\n",
    "import joblib\n",
    "import socket\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    html = \"<h3>Hello {name}!</h3>\" \\\n",
    "           \"<b>Hostname:</b> {hostname}<br/>\"\n",
    "    return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname())\n",
    "\n",
    "@app.route('/predict', methods=['GET','POST'])\n",
    "def predict():\n",
    "    \n",
    "    ## input checking\n",
    "    if not request.json:\n",
    "        print(\"ERROR: API (predict): did not receive request data\")\n",
    "        return jsonify([])\n",
    "\n",
    "    query = request.json\n",
    "    query = pd.DataFrame(query)\n",
    "    \n",
    "    if len(query.shape) == 1:\n",
    "         query = query.reshape(1, -1)\n",
    "\n",
    "    y_pred = model.predict(query)\n",
    "    \n",
    "    return(jsonify(y_pred.tolist()))        \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8080,debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
