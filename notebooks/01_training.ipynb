{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Recommendation System for Purchase Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Settings\n",
    "\n",
    "Prepare the enviroments with libraries and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "\n",
    "#Data\n",
    "import sqlalchemy as sql\n",
    "\n",
    "#Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor, BaselineOnly\n",
    "from surprise import KNNBasic,KNNWithMeans,KNNWithZScore,KNNBaseline\n",
    "from surprise import SVD,SVDpp,NMF\n",
    "from surprise import SlopeOne, CoClustering\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.accuracy import rmse, mae\n",
    "from surprise import dump\n",
    "\n",
    "#Model Tracking\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "# TRACKING_URI = 'http://mlflow:5000'\n",
    "# mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "#Utils\n",
    "import os\n",
    "import configparser\n",
    "from collections import defaultdict\n",
    "import tempfile\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment Variables\n",
    "outdata = '../data'\n",
    "outmodels = '../models'\n",
    "dbconnPath = './dbconn.properties'\n",
    "\n",
    "# Set dbconnection variables\n",
    "config = configparser.RawConfigParser()\n",
    "config.read(dbconnPath)\n",
    "params = config\n",
    "db_host=params.get('CONN', 'host')\n",
    "db_port=params.get('CONN', 'port')\n",
    "db_user=params.get('CONN', 'user')\n",
    "db_pwd=params.get('CONN', 'password')\n",
    "db_name=params.get('CONN', 'database')\n",
    "\n",
    "# Set connection string\n",
    "connection_str = f'mysql+pymysql://{db_user}:{db_pwd}@{db_host}:{db_port}/{db_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "We have to:\n",
    "\n",
    "1) Split each list of items in the products column into rows\n",
    "\n",
    "2) Count the number of products bought by a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database\n",
    "engine = sql.create_engine(connection_str)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database contains CUSTOMERID, TRANSACTIONS tables\n",
      "database contains CUSTOMERID table\n"
     ]
    }
   ],
   "source": [
    "print(f'{db_name} contains {engine.table_names()[0]}, {engine.table_names()[1]} tables')\n",
    "print(f'{db_name} contains {engine.table_names()[0]} table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tables in dataframes (Don't do that if you have a large dataset. Use just samples)\n",
    "df_cus = pd.read_sql(\"select * from CUSTOMERID\", connection)\n",
    "df_trx = pd.read_sql(\"select * from TRANSACTIONS\", connection)\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>27773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id customerId\n",
       "0   1       1553\n",
       "1   2      20400\n",
       "2   3      19750\n",
       "3   4       6334\n",
       "4   5      27773"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_cus.shape)\n",
    "df_cus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62483, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customerId</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2|2|23|68|68|111|29|86|107|152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>111|107|29|11|11|11|33|23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>164|227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2|2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id customerId                        products\n",
       "0   1          0                              20\n",
       "1   2          1  2|2|23|68|68|111|29|86|107|152\n",
       "2   3          2       111|107|29|11|11|11|33|23\n",
       "3   4          3                         164|227\n",
       "4   5          5                             2|2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_trx.shape)\n",
    "df_trx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_1=pd.DataFrame(df_trx.products.str.split('|').tolist(), index=df_trx.customerId)\\\n",
    ".stack()\\\n",
    ".reset_index()\\\n",
    ".groupby(['customerId', 0])\\\n",
    ".agg({0: 'count'})\\\n",
    ".rename(columns={0: 'purchase_count'})\\\n",
    ".reset_index()\\\n",
    ".rename(columns={0: 'productId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customerId productId  purchase_count\n",
      "0          0         1               2\n",
      "1          0        13               1\n",
      "2          0       136               2\n",
      "3          0       157               1\n",
      "4          0        19               3\n",
      "****************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 133585 entries, 0 to 133584\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   customerId      133585 non-null  object\n",
      " 1   productId       133585 non-null  object\n",
      " 2   purchase_count  133585 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data_prep_1.head())\n",
    "print('*'*40)\n",
    "print(data_prep_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's normalize data in a way to have a rank\n",
    "data_prep_2 = pd.pivot_table(data=data_prep_1, index='customerId', columns='productId', values='purchase_count', aggfunc='sum')\n",
    "data_prep_3 = (data_prep_2 - data_prep_2.min())/(data_prep_2.max() - data_prep_2.min())\n",
    "data_prep_4 = data_prep_3.reset_index().melt(id_vars=['customerId'], value_name='prod_ratings').dropna()\n",
    "data_prep_4.index = np.arange(0, len(data_prep_4))\n",
    "data_prep_4['prod_ratings'] = data_prep_4['prod_ratings'].apply(lambda x: int((round(x, 2))*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       customerId productId  prod_ratings\n",
      "1307            0         1             1\n",
      "54157           0        20             0\n",
      "49722           0       198             0\n",
      "46478           0        19             1\n",
      "116292          0        69             2\n"
     ]
    }
   ],
   "source": [
    "print(data_prep_4.sort_values(by=['customerId']).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we get **Triplet Representation** with each column representing user, item and the given rating respectively.\n",
    "Notice the rating goes from 0â€“100 (with 100 being the most number of purchase for an item and 0 being 0 purchase count for that item).\n",
    "It's a kind of preference for each user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "Explore syntetic ratings by UserID and ProductID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt1=data_prep_4['prod_ratings']\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "plt.hist(df_plt1)\n",
    "ax.set_xlabel('Syntetic Product Ratings')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Rating Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Distribution by ProductId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt_2=data_prep_4.groupby('productId')['prod_ratings'].count().reset_index()[0:50]\n",
    "df_plt_2\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "plt.bar(df_plt_2.productId, df_plt_2.prod_ratings, )\n",
    "ax.set_xlabel('Number of Ratings per product')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Rating Distribution by ProductId')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt_2.sort_values(by='prod_ratings', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt_2=data_prep_4.groupby('productId')['prod_ratings'].count()\n",
    "df_plt_2\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "plt.hist(df_plt_2)\n",
    "ax.set_xlabel('Number of Ratings')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Rating Distribution by ProductId')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Distribution By User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt_3=data_prep_4.groupby('customerId')['prod_ratings'].count().reset_index()[0:50]\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "plt.bar(df_plt_3.customerId, df_plt_3.prod_ratings)\n",
    "ax.set_xlabel('Number of Ratings per Customer')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Rating Distribution by customerId')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt_3.sort_values(by='prod_ratings', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt_3=data_prep_4.groupby('customerId')['prod_ratings'].count()\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "plt.hist(df_plt_3)\n",
    "ax.set_xlabel('Number of Ratings per Customer')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Rating Distribution by customerId')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "To do that, I use **Surprise** which is an easy-to-use Python scikit for recommender systems.\n",
    "\n",
    "I follow the Getting Started (https://surprise.readthedocs.io/en/stable/getting_started.html#getting-started)\n",
    "\n",
    "Reference: https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings and Utility Functions (mlflow_tracker, get_Iu, get_Ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "BucketAlreadyOwnedByYou",
     "evalue": "BucketAlreadyOwnedByYou: message: Your previous request to create the named bucket succeeded and you already own it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBucketAlreadyOwnedByYou\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/work/ModelOps/notebooks/00_set_bucket.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mminioClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mlflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mResponseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/minio/api.py\u001b[0m in \u001b[0;36mmake_bucket\u001b[0;34m(self, bucket_name, location)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_bucket_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBucketAlreadyOwnedByYou\u001b[0m: BucketAlreadyOwnedByYou: message: Your previous request to create the named bucket succeeded and you already own it."
     ]
    }
   ],
   "source": [
    "# A reader is required with the rating_scale param\n",
    "mindata = data_prep_4.prod_ratings.min()\n",
    "maxdata = data_prep_4.prod_ratings.max()\n",
    "reader = Reader(rating_scale=(mindata,maxdata))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order)\n",
    "data_prep_5 = data_prep_4.rename(columns={'customerId': 'userID', 'productId':'itemID', 'prod_ratings':'rating'})\n",
    "data_prep_5.to_csv(os.path.join(outdata, 'sample_toscore.csv'))\n",
    "data = Dataset.load_from_df(data_prep_5[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "#Create the experiment\n",
    "mlflow.set_experiment('Purchase Recommended System')\n",
    "\n",
    "#Create Minio Bucket for Artefact Storage\n",
    "%run -t 00_set_bucket.ipynb\n",
    "\n",
    "\n",
    "def mlflow_tracker(reader_data, algo, params, rundesc='myrun'):\n",
    "    \"\"\" \n",
    "    return the run id and experiment id of each model\n",
    "    args: \n",
    "      reader_data: data parsed with Reader class \n",
    "      params: paramters of cross_validate function\n",
    "      rundesc: A description to populate exoeriment note\n",
    "      \n",
    "    returns: \n",
    "      run_id and experiment_id\n",
    "    \"\"\"\n",
    "        \n",
    "    # Store Algo name\n",
    "    algo_name = str(algo.__class__.__name__)\n",
    "\n",
    "    with mlflow.start_run(run_name=algo_name) as run:\n",
    "\n",
    "        # Store run_id and experiment_id\n",
    "        run_id=run.info.run_uuid\n",
    "        experiment_id=run.info.experiment_id\n",
    "        \n",
    "        #Create model instance\n",
    "        redic=cross_validate(algo, reader_data, **params)\n",
    "        #Create a dataframe of means\n",
    "        recdf=pd.DataFrame.from_dict(redic).mean(axis=0)\n",
    "\n",
    "        #Log params\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric('test_time', recdf.iloc[3])\n",
    "        mlflow.log_metric('test_rmse_mean', recdf.iloc[0])\n",
    "        mlflow.log_metric('test_mae_mean', recdf.iloc[1])\n",
    "        mlflow.log_metric('fit_time', recdf.iloc[2])\n",
    "\n",
    "        # Set the notes for Runs\n",
    "\n",
    "        MlflowClient().set_tag(run_id,\n",
    "                               \"mlflow.note.content\",\n",
    "                               rundesc)\n",
    "\n",
    "    return (run_id, experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage: Automatic cross-validation\n",
    "\n",
    "#### Basic Algorithms\n",
    "\n",
    "##### random_pred.NormalPredictor\n",
    "Algorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "##### baseline_only.BaselineOnly\n",
    "Algorithm predicting the baseline estimate for given user and item.\n",
    "\n",
    "#### KNN algorithms\n",
    "\n",
    "##### knns.KNNBasic\n",
    "A basic collaborative filtering algorithm\n",
    "##### knns.KNNWithMeans\n",
    "A basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "##### knns.KNNWithZScore\n",
    "A basic collaborative filtering algorithm, taking into account taking into account the z-score normalization of each user.\n",
    "##### knns.KNNBaseline\n",
    "A basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "\n",
    "#### Matrix Factorization-based algorithms\n",
    "##### matrix_factorization.SVD\n",
    "The famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize.When baselines are not used, this is equivalent to Probabilistic Matrix Factorization\n",
    "##### matrix_factorization.SVDpp\n",
    "The SVD++ algorithm, an extension of SVD taking into account implicit ratings.\n",
    "##### matrix_factorization.NMF\n",
    "A collaborative filtering algorithm based on Non-negative Matrix Factorization.\n",
    "\n",
    "#### Other Algorithms\n",
    "##### slope_one.SlopeOne\n",
    "A simple yet accurate collaborative filtering algorithm.\n",
    "##### co_clustering.CoClustering\n",
    "A collaborative filtering algorithm based on co-clustering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'measures': ['RMSE', 'MAE'], 'cv':3, 'verbose': False}\n",
    "algos = [BaselineOnly(), NormalPredictor(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), KNNBaseline(), SVD(), SVDpp(), SlopeOne(), CoClustering()]\n",
    "\n",
    "for algo in algos:\n",
    "    mlflow_tracker(data, algo, params)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:  Based on the Mlflow tracking service, the best model is BaselineOnly algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparer(data, test_size=0.25):\n",
    "    \"\"\" \n",
    "    return train and test sets \n",
    "    args: \n",
    "      data: data parsed with Reader class \n",
    "    returns: \n",
    "      trainset and testset\n",
    "    \"\"\"\n",
    "    trainset, testset = train_test_split(data, test_size=test_size)\n",
    "    return trainset, testset\n",
    "\n",
    "def trainer(trainset, bsl_options):\n",
    "    \"\"\" \n",
    "    return trained model \n",
    "    args: \n",
    "      trainset: training data parsed with Reader class\n",
    "      bsl_option: algorithm options \n",
    "    returns: \n",
    "      trained model\n",
    "    \"\"\"\n",
    "    algo = BaselineOnly(bsl_options=bsl_options)\n",
    "    model = algo.fit(trainset)\n",
    "    return model\n",
    "\n",
    "def predictor(model, testset):\n",
    "    \"\"\" \n",
    "    return trained model and predictions\n",
    "    args: \n",
    "      model: trained model\n",
    "      testset: test data parsed with Reader class \n",
    "    returns: \n",
    "      trained model\n",
    "    \"\"\"\n",
    "    predictions = model.test(testset)\n",
    "    return model, predictions\n",
    "\n",
    "def tuner(data, bsl_options_grid, param_model):\n",
    "    \"\"\" \n",
    "    return model parameters, tuning history and best tuned model\n",
    "    args: \n",
    "      data: data parsed with Reader class \n",
    "      bsl_options_grid:  algorithm options grid\n",
    "      param_model: error measures and cross validation parameters \n",
    "    returns: \n",
    "      param_model, history_tune, tuned_model\n",
    "    \"\"\"\n",
    "    \n",
    "    gs = GridSearchCV(BaselineOnly, bsl_options_grid, **param_model)\n",
    "    gs.fit(data)\n",
    "    \n",
    "    history_tune=pd.DataFrame.from_dict(gs.cv_results)\n",
    "    \n",
    "    best_bsl_options = gs.best_params['rmse']\n",
    "    \n",
    "    train, test = preparer(data)\n",
    "    tuned_model = trainer(train, best_bsl_options)\n",
    "    \n",
    "    return param_model, history_tune, tuned_model\n",
    "\n",
    " # Define utils functions for prediction readability\n",
    "\n",
    "def get_Iu(trainset, uid):\n",
    "    \"\"\"\n",
    "    return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "\n",
    "def get_Ui(trainset, iid):\n",
    "    \"\"\"\n",
    "    return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "def mlflow_tune_tracker(data, algo_name, param_grid, param_model, rundesc='myruntuned'):\n",
    "    \"\"\" \n",
    "    return the run id and experiment id of tuned model\n",
    "    args: \n",
    "      algo_name: the name of tuned algorithm \n",
    "      param_grid:  algorithm options grid\n",
    "      param_model: error measures and cross validation parameters \n",
    "    returns: \n",
    "      run_id, experiment_id\n",
    "    \"\"\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=algo_name) as run:\n",
    "\n",
    "        # Store run_id and experiment_id\n",
    "        run_id=run.info.run_uuid\n",
    "        experiment_id=run.info.experiment_id\n",
    "\n",
    "        #Train the model\n",
    "        trainset, testset = preparer(data)\n",
    "\n",
    "        #Tune\n",
    "        params, history_tune, tuned_model = tuner(data, param_grid, param_model)\n",
    "\n",
    "        #History\n",
    "        for index, row in history_tune.iterrows():\n",
    "            with mlflow.start_run(experiment_id=experiment_id, run_name=algo_name + str(index), nested=True) as subruns:\n",
    "\n",
    "                bsl_options = row['params']\n",
    "                params_tune = {**params, **bsl_options}\n",
    "\n",
    "                #Log params\n",
    "                mlflow.log_params(params_tune)\n",
    "                mlflow.log_metric('fit_time',round(row['mean_fit_time'], 3))\n",
    "                mlflow.log_metric('test_time', round(row['mean_test_time'], 3))\n",
    "                mlflow.log_metric('test_rmse_mean', round(row['mean_test_rmse'], 3))\n",
    "                mlflow.log_metric('test_mae_mean', round(row['mean_test_mae'], 3))\n",
    "\n",
    "                #Log Model (artefact)\n",
    "                temp = tempfile.NamedTemporaryFile(prefix=\"model\", suffix=\".pkl\")\n",
    "                temp_name = temp.name\n",
    "                try:\n",
    "                    model, predictions = predictor(trainer(trainset, bsl_options), testset)\n",
    "                    dump.dump(temp_name, predictions, model)\n",
    "                    mlflow.log_artifact(temp_name, 'model')\n",
    "                finally:\n",
    "                    temp.close()\n",
    "\n",
    "                 #Log best predictions\n",
    "                df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "                df['Iu'] = [get_Iu(trainset, uid) for uid in df.uid]\n",
    "                df['Ui'] = [get_Ui(trainset, iid) for iid in df.iid]\n",
    "                df['err'] = abs(df.est - df.rui)\n",
    "                best_predictions = df.sort_values(by='err')[:10]\n",
    "                temp = tempfile.NamedTemporaryFile(prefix=\"best-predicitions\", suffix=\".csv\")\n",
    "                temp_name = temp.name\n",
    "                try:\n",
    "                    best_predictions.to_csv(temp_name, index=False)\n",
    "                    mlflow.log_artifact(temp_name)\n",
    "                finally:\n",
    "                    temp.close()\n",
    "                    \n",
    "        MlflowClient().set_tag(run_id,\n",
    "                   \"mlflow.note.content\",\n",
    "                   rundesc)\n",
    "\n",
    "    return run_id, experiment_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'bsl_options' : {'method': ['als', 'sgd'],\n",
    "              'n_epochs': [5, 15],\n",
    "              'reg_u': [10, 20],\n",
    "              'reg_i': [5,15]               \n",
    "                }\n",
    "              }\n",
    "\n",
    "param_model = {\n",
    "          'measures': ['RMSE', 'MAE'], \n",
    "          'cv':3\n",
    "            }\n",
    "\n",
    "run_id, experiment_id = mlflow_tune_tracker(data, 'BaselineOnly', param_grid, param_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Model validation\n",
    "\n",
    "Comment the best and the worst predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the best parameter combination**\n",
    "\n",
    "Then the best model is BaselineOnly with \n",
    "- method: 'als'\n",
    "- n_epochs: 15\n",
    "- reg_u: 10\n",
    "- reg_i: 5\n",
    "\n",
    "**Compare to all the experiments we ran so we validate the model as the best one based on RMSE metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test and comment predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ALS\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "print('Using ALS')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 15,\n",
    "               'reg_u': 10,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "algo_best = BaselineOnly(bsl_options=bsl_options)\n",
    "predictions = algo_best.fit(trainset).test(testset)\n",
    "\n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['Iu'] = [get_Iu(trainset, uid) for uid in df.uid]\n",
    "df['Ui'] = [get_Ui(trainset, iid) for iid in df.iid]\n",
    "df['err'] = abs(df.est - df.rui)\n",
    "best_predictions = df.sort_values(by='err')[:10]\n",
    "worst_predictions = df.sort_values(by='err')[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "      <th>Iu</th>\n",
       "      <th>Ui</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13621</th>\n",
       "      <td>3698</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>5</td>\n",
       "      <td>775</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26048</th>\n",
       "      <td>20748</td>\n",
       "      <td>219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>8</td>\n",
       "      <td>275</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>12114</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>5</td>\n",
       "      <td>830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14365</th>\n",
       "      <td>14149</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>5</td>\n",
       "      <td>924</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>7848</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>9</td>\n",
       "      <td>2792</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21424</th>\n",
       "      <td>7614</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>4</td>\n",
       "      <td>213</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>18069</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>5</td>\n",
       "      <td>924</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17296</th>\n",
       "      <td>10633</td>\n",
       "      <td>153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>12</td>\n",
       "      <td>323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30232</th>\n",
       "      <td>13679</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>8</td>\n",
       "      <td>649</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19269</th>\n",
       "      <td>21941</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>8</td>\n",
       "      <td>411</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid  iid  rui  est                    details  Iu    Ui  err\n",
       "13621   3698   25  0.0  0.0  {'was_impossible': False}   5   775  0.0\n",
       "26048  20748  219  0.0  0.0  {'was_impossible': False}   8   275  0.0\n",
       "6612   12114   17  0.0  0.0  {'was_impossible': False}   5   830  0.0\n",
       "14365  14149   14  0.0  0.0  {'was_impossible': False}   5   924  0.0\n",
       "4214    7848    2  0.0  0.0  {'was_impossible': False}   9  2792  0.0\n",
       "21424   7614   82  0.0  0.0  {'was_impossible': False}   4   213  0.0\n",
       "2864   18069   14  0.0  0.0  {'was_impossible': False}   5   924  0.0\n",
       "17296  10633  153  0.0  0.0  {'was_impossible': False}  12   323  0.0\n",
       "30232  13679   16  0.0  0.0  {'was_impossible': False}   8   649  0.0\n",
       "19269  21941   92  0.0  0.0  {'was_impossible': False}   8   411  0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**: Because Ui is anywhere between 275 to 2792, it's good because we have a lot of people who buy the product (a kind of preference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "      <th>Iu</th>\n",
       "      <th>Ui</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>3</td>\n",
       "      <td>196</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.353682</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>3</td>\n",
       "      <td>275</td>\n",
       "      <td>9.646318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>3260</td>\n",
       "      <td>23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.298553</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>16</td>\n",
       "      <td>603</td>\n",
       "      <td>9.701447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>22548</td>\n",
       "      <td>122</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.265711</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>4</td>\n",
       "      <td>347</td>\n",
       "      <td>9.734289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>9360</td>\n",
       "      <td>209</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.247787</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>13</td>\n",
       "      <td>269</td>\n",
       "      <td>9.752213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>229</td>\n",
       "      <td>275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.238495</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>11</td>\n",
       "      <td>215</td>\n",
       "      <td>9.761505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>17425</td>\n",
       "      <td>224</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.218142</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>9.781858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31559</th>\n",
       "      <td>6462</td>\n",
       "      <td>116</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.182018</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>4</td>\n",
       "      <td>364</td>\n",
       "      <td>9.817982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>3062</td>\n",
       "      <td>47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.053785</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>30</td>\n",
       "      <td>494</td>\n",
       "      <td>9.946215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28152</th>\n",
       "      <td>6688</td>\n",
       "      <td>25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>5</td>\n",
       "      <td>775</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20464</th>\n",
       "      <td>1404</td>\n",
       "      <td>148</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>14</td>\n",
       "      <td>227</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid  iid   rui       est                    details  Iu   Ui  \\\n",
       "15589      3  196  10.0  0.353682  {'was_impossible': False}   3  275   \n",
       "4508    3260   23  10.0  0.298553  {'was_impossible': False}  16  603   \n",
       "2966   22548  122  10.0  0.265711  {'was_impossible': False}   4  347   \n",
       "572     9360  209  10.0  0.247787  {'was_impossible': False}  13  269   \n",
       "24834    229  275  10.0  0.238495  {'was_impossible': False}  11  215   \n",
       "715    17425  224  10.0  0.218142  {'was_impossible': False}   1  267   \n",
       "31559   6462  116  10.0  0.182018  {'was_impossible': False}   4  364   \n",
       "328     3062   47  10.0  0.053785  {'was_impossible': False}  30  494   \n",
       "28152   6688   25  10.0  0.000000  {'was_impossible': False}   5  775   \n",
       "20464   1404  148  10.0  0.000000  {'was_impossible': False}  14  227   \n",
       "\n",
       "             err  \n",
       "15589   9.646318  \n",
       "4508    9.701447  \n",
       "2966    9.734289  \n",
       "572     9.752213  \n",
       "24834   9.761505  \n",
       "715     9.781858  \n",
       "31559   9.817982  \n",
       "328     9.946215  \n",
       "28152  10.000000  \n",
       "20464  10.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**: Really bad. Because consider the item 148, the user buy it 0 times but the algorithm says he buy always, Also if we look at distribution only few people buy it frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_prep_4.loc[data_prep_4['productId'] == '148']['prod_ratings'].hist()\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('Number of ratings')\n",
    "plt.title('Number of ratings 148 has received')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Model Registration\n",
    "\n",
    "Register the Model in the Mlflow Model Registry and set its status as STAGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Champion' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'Champion'.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Champion'\n",
    "artifact_path = \"model\"\n",
    "model_uri = \"runs:/{run_id}/{artifact_path}\".format(run_id=run_id, artifact_path=artifact_path)\n",
    "\n",
    "model_details = mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model stage is: 'Staging'\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "client.update_registered_model(\n",
    "  name=model_details.name,\n",
    "  description=\"This model provides recommendation for specific users and items based on purchase data. The data consists of user transactions\"\n",
    ")\n",
    "\n",
    "client.update_model_version(\n",
    "  name=model_details.name,\n",
    "  version=model_details.version,\n",
    "  description=\"This model was built with Surprise library. It is a ALS based BaselineOnly algorithm\"\n",
    ")\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "  name=model_details.name,\n",
    "  version=model_details.version,\n",
    "  stage='Staging',\n",
    ")\n",
    "model_version_details = client.get_model_version(\n",
    "  name=model_details.name,\n",
    "  version=model_details.version,\n",
    ")\n",
    "print(\"The current model stage is: '{stage}'\".format(stage=model_version_details.current_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
