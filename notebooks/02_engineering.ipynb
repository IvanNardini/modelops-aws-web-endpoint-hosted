{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build a Recommendation System for Purchase Data\n",
    "\n",
    "The scope of this notebook is \n",
    "\n",
    "- Code the Scoring Function\n",
    "- Unit Test the Score\n",
    "- Build the Dash Applimcation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Science\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Model Tracking\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import ResponseError\n",
    "\n",
    "from surprise import dump\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#Utils\n",
    "from pprint import pprint\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enviroment variables\n",
    "\n",
    "outmodels = '../models/'\n",
    "artefact_name = '4fa76aa5e00c413db3e23810a913dc8e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model Artefact from the Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "for regmodel in client.list_registered_models():\n",
    "    regmodel_info = dict(regmodel)\n",
    "\n",
    "# pprint(regmodel_info, indent=3)\n",
    "\n",
    "champion=client.get_registered_model('Champion')\n",
    "championid=champion.latest_versions[-1].run_id\n",
    "\n",
    "art_list = [arts.path for arts in client.list_artifacts(championid, path=None)]\n",
    "\n",
    "for art_path in art_list: \n",
    "    client.download_artifacts(championid, art_path, outmodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Check Model Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid='10929', iid='261', r_ui=0.0, est=0.3747662865053879, details={'was_impossible': False}), Prediction(uid='2715', iid='256', r_ui=0.0, est=1.397448561679778, details={'was_impossible': False}), Prediction(uid='12786', iid='198', r_ui=0.0, est=0.34800521979059373, details={'was_impossible': False}), Prediction(uid='38', iid='119', r_ui=0.0, est=1.4081730858161146, details={'was_impossible': False}), Prediction(uid='8417', iid='2', r_ui=0.0, est=0.10200631019335304, details={'was_impossible': False}), Prediction(uid='5370', iid='293', r_ui=0.0, est=1.4426131167097673, details={'was_impossible': False}), Prediction(uid='225', iid='34', r_ui=0.0, est=0.6310815188817669, details={'was_impossible': False}), Prediction(uid='12930', iid='24', r_ui=2.0, est=0.5743177052276057, details={'was_impossible': False}), Prediction(uid='9481', iid='261', r_ui=0.0, est=0.45208051960508466, details={'was_impossible': False}), Prediction(uid='2410', iid='49', r_ui=0.0, est=0.7374420578118797, details={'was_impossible': False})]\n",
      "****************************************************************************************************\n",
      "<surprise.prediction_algorithms.baseline_only.BaselineOnly object at 0x7fa152758210>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33397"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelpkl = \"\".join([outmodels, 'model/model_gm2xt4q.pkl'])\n",
    "predictions, algo = dump.load(modelpkl)\n",
    "\n",
    "print(predictions[0:10])\n",
    "print('*'*100)\n",
    "print(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = data_prep_4.head()\n",
    "test_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = str(1007)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(0)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo_best.predict(uid, iid, r_ui=13, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_5['predictions'] = data_prep_5.apply(lambda row:algo_best.predict(row['userID'], \n",
    "                     row['itemID'], row['rating']), axis = 1)\n",
    "data_prep_5.head()\n",
    "# predictions=list(data_prep_5['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Recommended Items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "#     # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_top_n_ui(top, ui):\n",
    "    try:\n",
    "        return {k:v for k,v in top.items() if ui==k}\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_top_n_ui(get_top_n(predictions, n=10), '20400'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
